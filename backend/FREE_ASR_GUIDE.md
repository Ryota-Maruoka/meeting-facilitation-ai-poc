# ğŸ†“ ç„¡æ–™ASRå®Ÿè£…ã‚¬ã‚¤ãƒ‰

å®Œå…¨ç„¡æ–™ã§éŸ³å£°èªè­˜æ©Ÿèƒ½ã‚’å®Ÿè£…ã™ã‚‹æ–¹æ³•ã‚’èª¬æ˜ã—ã¾ã™ã€‚

## ğŸ¯ ç„¡æ–™ASRã‚ªãƒ—ã‚·ãƒ§ãƒ³

### 1. **Whisper.cpp**ï¼ˆæ¨å¥¨ï¼‰
- **ã‚³ã‚¹ãƒˆ**: å®Œå…¨ç„¡æ–™
- **ç²¾åº¦**: é«˜ï¼ˆOpenAI Whisperã¨åŒç­‰ï¼‰
- **é€Ÿåº¦**: ä¸­ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œï¼‰
- **ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—**: ç°¡å˜

### 2. **ãƒ–ãƒ©ã‚¦ã‚¶ã®Web Speech API**
- **ã‚³ã‚¹ãƒˆ**: å®Œå…¨ç„¡æ–™
- **ç²¾åº¦**: ä¸­ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ä¾å­˜ï¼‰
- **é€Ÿåº¦**: é€Ÿï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰
- **ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—**: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰å®Ÿè£…

### 3. **ã‚¹ã‚¿ãƒ–å®Ÿè£…**
- **ã‚³ã‚¹ãƒˆ**: å®Œå…¨ç„¡æ–™
- **ç²¾åº¦**: ãªã—ï¼ˆé–‹ç™ºç”¨ï¼‰
- **é€Ÿåº¦**: é€Ÿ
- **ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—**: ä¸è¦

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### è‡ªå‹•ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆæ¨å¥¨ï¼‰

```bash
# ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§å®Ÿè¡Œ
cd backend
python setup_free_asr.py
```

### æ‰‹å‹•ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

#### 1. Whisper.cppã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
# 1. Whisper.cppã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
# https://github.com/ggerganov/whisper.cpp/releases
# whisper-bin-x64.zip ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

# 2. å±•é–‹
unzip whisper-bin-x64.zip
mv whisper-cpp whisper-cpp

# 3. ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
cd whisper-cpp
mkdir models
cd models
# ggml-base.bin ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆç´„1.5GBï¼‰
wget https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.bin

# 4. ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š
echo "WHISPER_EXECUTABLE_PATH=./whisper-cpp/whisper.exe" > .env
echo "WHISPER_MODEL_PATH=./whisper-cpp/models/ggml-base.bin" >> .env
echo "ASR_LANGUAGE=ja" >> .env
```

#### 2. ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

```bash
# ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
python run.py

# åˆ¥ã®ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ãƒ†ã‚¹ãƒˆ
curl -X POST "http://localhost:8000/meetings/{meeting_id}/transcribe" \
     -H "Content-Type: multipart/form-data" \
     -F "file=@test_audio.wav"
```

## ğŸ”§ è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³

### ç’°å¢ƒå¤‰æ•°

```bash
# .env ãƒ•ã‚¡ã‚¤ãƒ«
ASR_PROVIDER=whisper_cpp          # whisper_cpp, browser_api, stub
WHISPER_EXECUTABLE_PATH=./whisper-cpp/whisper.exe
WHISPER_MODEL_PATH=./whisper-cpp/models/ggml-base.bin
ASR_LANGUAGE=ja                   # ja, en, auto
ASR_TEMPERATURE=0.0               # 0.0-1.0
```

### ãƒ¢ãƒ‡ãƒ«é¸æŠ

| ãƒ¢ãƒ‡ãƒ« | ã‚µã‚¤ã‚º | ç²¾åº¦ | é€Ÿåº¦ | ç”¨é€” |
|--------|--------|------|------|------|
| tiny | 39MB | ä½ | é€Ÿ | é–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆ |
| base | 142MB | ä¸­ | ä¸­ | ä¸€èˆ¬ç”¨é€” |
| small | 466MB | é«˜ | é… | é«˜ç²¾åº¦ |
| medium | 1.5GB | é«˜ | é… | æœ€é«˜ç²¾åº¦ |

## ğŸŒ ãƒ–ãƒ©ã‚¦ã‚¶APIå®Ÿè£…

ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã§Web Speech APIã‚’ä½¿ç”¨ã™ã‚‹å ´åˆï¼š

```javascript
// ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰å®Ÿè£…ä¾‹
const recognition = new webkitSpeechRecognition();
recognition.lang = 'ja-JP';
recognition.continuous = true;
recognition.interimResults = true;

recognition.onresult = (event) => {
  const transcript = event.results[event.results.length - 1][0].transcript;
  // ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«é€ä¿¡
  sendTranscript(transcript);
};

recognition.start();
```

## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ

| æ–¹å¼ | ã‚³ã‚¹ãƒˆ | ç²¾åº¦ | é€Ÿåº¦ | ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ | ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— |
|------|--------|------|------|------------|------------|
| Whisper.cpp | ç„¡æ–™ | é«˜ | ä¸­ | ãƒ­ãƒ¼ã‚«ãƒ« | ç°¡å˜ |
| Web Speech API | ç„¡æ–™ | ä¸­ | é€Ÿ | ãƒ–ãƒ©ã‚¦ã‚¶ | ä¸­ |
| ã‚¹ã‚¿ãƒ– | ç„¡æ–™ | ãªã— | é€Ÿ | ãƒ­ãƒ¼ã‚«ãƒ« | ä¸è¦ |

## ğŸ› ï¸ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### Whisper.cpp

**ã‚¨ãƒ©ãƒ¼**: `FileNotFoundError: Whisper.cpp not found`
```bash
# è§£æ±ºæ–¹æ³•
export WHISPER_EXECUTABLE_PATH=/path/to/whisper.exe
```

**ã‚¨ãƒ©ãƒ¼**: `Model file not found`
```bash
# è§£æ±ºæ–¹æ³•
export WHISPER_MODEL_PATH=/path/to/ggml-base.bin
```

**ã‚¨ãƒ©ãƒ¼**: `subprocess.TimeoutExpired`
```bash
# è§£æ±ºæ–¹æ³•: ã‚ˆã‚Šå°ã•ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
# tinyãƒ¢ãƒ‡ãƒ«ï¼ˆ39MBï¼‰ã‚’è©¦ã™
```

### ãƒ–ãƒ©ã‚¦ã‚¶API

**ã‚¨ãƒ©ãƒ¼**: `webkitSpeechRecognition is not defined`
```javascript
// è§£æ±ºæ–¹æ³•: HTTPSç’°å¢ƒã§å®Ÿè¡Œ
// ã¾ãŸã¯Chrome/Edgeãƒ–ãƒ©ã‚¦ã‚¶ã‚’ä½¿ç”¨
```

## ğŸš€ æœ¬ç•ªç’°å¢ƒã§ã®æ¨å¥¨è¨­å®š

### é–‹ç™ºç’°å¢ƒ
- **æ¨å¥¨**: ã‚¹ã‚¿ãƒ–å®Ÿè£…
- **ç†ç”±**: ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸è¦ã€é«˜é€Ÿ

### ãƒ†ã‚¹ãƒˆç’°å¢ƒ
- **æ¨å¥¨**: Whisper.cpp (tiny model)
- **ç†ç”±**: è»½é‡ã€é«˜é€Ÿã€ç„¡æ–™

### æœ¬ç•ªç’°å¢ƒ
- **æ¨å¥¨**: Whisper.cpp (base model)
- **ç†ç”±**: é«˜ç²¾åº¦ã€ç„¡æ–™ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·

## ğŸ“ å®Ÿè£…ä¾‹

### ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼ˆPythonï¼‰

```python
from app.services.free_asr import transcribe_audio

# éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—
with open("audio.wav", "rb") as f:
    audio_data = f.read()

chunks = transcribe_audio(audio_data)
for chunk in chunks:
    print(f"{chunk['start_sec']:.1f}s: {chunk['text']}")
```

### ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ï¼ˆJavaScriptï¼‰

```javascript
// éŸ³å£°éŒ²éŸ³
const mediaRecorder = new MediaRecorder(stream);
const audioChunks = [];

mediaRecorder.ondataavailable = (event) => {
  audioChunks.push(event.data);
};

mediaRecorder.onstop = () => {
  const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
  
  // ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«é€ä¿¡
  const formData = new FormData();
  formData.append('file', audioBlob);
  
  fetch('/meetings/123/transcribe', {
    method: 'POST',
    body: formData
  });
};
```

## ğŸ‰ å®Œäº†ï¼

ã“ã‚Œã§å®Œå…¨ç„¡æ–™ã®éŸ³å£°èªè­˜æ©Ÿèƒ½ãŒå®Ÿè£…ã§ãã¾ã—ãŸï¼

- âœ… ã‚³ã‚¹ãƒˆ: 0å††
- âœ… ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼: ãƒ­ãƒ¼ã‚«ãƒ«å‡¦ç†
- âœ… ç²¾åº¦: é«˜ï¼ˆWhisper.cppä½¿ç”¨æ™‚ï¼‰
- âœ… ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—: è‡ªå‹•åŒ–æ¸ˆã¿
